# SLT-LAT 
Code accompanying the paper     
Locality-Aware Transformer for Video-Based Sign Language Translation             
Accepted by the Journal of IEEE Signal Processing Letters.          
## Requirements
Pytorch, Shift
## Datasets
The PHOENIX14T dataset can be downloaded from [here](https://github.com/neccam/slt).              
The CSL dataset can be downloaded from [here](https://ustc-slr.github.io/datasets/2015_csl/).
## Code
The code is based on [fpt4slt](https://github.com/m-decoster/fpt4slt) and [Shift Operation](https://github.com/kchengiva/Shift-GCN).
## Citation
If you use any part of this code in your research, please cite our paper:      
@article{guo2023locality,                   
  title={Locality-Aware Transformer for Video-Based Sign Language Translation},                  
  author={Guo, Zihui and Hou, Yonghong and Hou, Chunping and Yin, Wenjie},                    
  journal={IEEE Signal Processing Letters},                 
  volume={30},                
  pages={364--368},             
  year={2023},                
  publisher={IEEE}                      
}
